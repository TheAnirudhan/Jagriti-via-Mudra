{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Fusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import keras\n",
    "import runai.ga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_rgb_stream\n",
    "class Build_Fusion_Model:\n",
    "    # build_ssd\n",
    "    def build_ssd_stream(self):\n",
    "        base_model = MobileNetV2(input_shape=(320, 320, 3), include_top=False, weights='imagenet')\n",
    "        # Freeze the base model layers\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "        self.model = Model(inputs=base_model.input, outputs=x)\n",
    "        # print(self.model.summary())\n",
    "        return self.model\n",
    "    \n",
    "    # build_pose_stream\n",
    "    def build_pose_stream(self,input_shape=(20, 17*2)):\n",
    "        self.model = models.Sequential()\n",
    "\n",
    "        # Add LSTM layers for processing pose keypoints over time\n",
    "        self.model.add(layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
    "        self.model.add(layers.LSTM(128, return_sequences=True))\n",
    "        self.model.add(layers.LSTM(256, return_sequences=True))\n",
    "\n",
    "        self.model.add(layers.Dense(256, activation='relu'))\n",
    "        self.model.add(layers.Dropout(0.5))\n",
    "\n",
    "        return self.model\n",
    "\n",
    "# build_fusion_model\n",
    "    def build_fusion_model(self,ssd_stream, pose_stream, num_classes):\n",
    "        # Combine the two streams\n",
    "        self.ssd_stream_flattened = layers.Flatten()(ssd_stream.output)\n",
    "        self.pose_stream_flattened = layers.Flatten()(pose_stream.output)\n",
    "        combined_input = layers.concatenate([self.pose_stream_flattened, self.ssd_stream_flattened])\n",
    "\n",
    "        # Add fully connected layers for fusion\n",
    "        self.fusion_dense = layers.Dense(512, activation='relu')(combined_input) # replace with (combined_input)\n",
    "        self.fusion_dense = layers.Dropout(0.5)(self.fusion_dense)\n",
    "\n",
    "        self.fusion_output = layers.Dense(num_classes, activation='sigmoid')(self.fusion_dense)\n",
    "\n",
    "        # Create the final model\n",
    "        self.fusion_model = models.Model(inputs=[pose_stream.input, ssd_stream.input], outputs=self.fusion_output)\n",
    "\n",
    "        return self.fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'runai.ga' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Compile the model with an appropriate optimizer, loss, and metrics\u001b[39;00m\n\u001b[0;32m     27\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam()\n\u001b[1;32m---> 28\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mrunai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mga\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m     29\u001b[0m fusion_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Display the model summary\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# fusion_model.summary()\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'runai.ga' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "# Set the number of classes for your action recognition task\n",
    "num_classes = 1\n",
    "build_model = Build_Fusion_Model()\n",
    "# Build the RGB stream\n",
    "ssd_stream = build_model.build_ssd_stream()\n",
    "\n",
    "# Build the Pose stream\n",
    "pose_stream = build_model.build_pose_stream(input_shape=(10, 34))\n",
    "\n",
    "# Build the Fusion model\n",
    "fusion_model = build_model.build_fusion_model(ssd_stream, pose_stream, num_classes)\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "hp_epochs = hp.HParam('epochs', hp.IntInterval(10, 50))\n",
    "hp_learning_rate = hp.HParam('learning_rate', hp.RealInterval(1e-4, 1e-2))\n",
    "\n",
    "# Create a summary file for TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Create a callback for hyperparameter logging\n",
    "hparams_callback = hp.KerasCallback(log_dir, hparams={hp_epochs: 20, hp_learning_rate: 1e-3})\n",
    "\n",
    "\n",
    "# Compile the model with an appropriate optimizer, loss, and metrics\n",
    "optimizer = keras.optimizers.Adam()\n",
    "optimizer = runai.ga.keras.optimizers.Adam(steps=128)\n",
    "fusion_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "# fusion_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(fusion_model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 10, 34), (None, 320, 320, 3)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from video_processor import VideoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/KTH/boxing\\person01_boxing_d1_unco...</td>\n",
       "      <td>boxing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/KTH/boxing\\person01_boxing_d2_unco...</td>\n",
       "      <td>boxing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/KTH/boxing\\person01_boxing_d3_unco...</td>\n",
       "      <td>boxing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/KTH/boxing\\person01_boxing_d4_unco...</td>\n",
       "      <td>boxing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/KTH/boxing\\person02_boxing_d1_unco...</td>\n",
       "      <td>boxing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clip_path   label\n",
       "0  ../datasets/KTH/boxing\\person01_boxing_d1_unco...  boxing\n",
       "1  ../datasets/KTH/boxing\\person01_boxing_d2_unco...  boxing\n",
       "2  ../datasets/KTH/boxing\\person01_boxing_d3_unco...  boxing\n",
       "3  ../datasets/KTH/boxing\\person01_boxing_d4_unco...  boxing\n",
       "4  ../datasets/KTH/boxing\\person02_boxing_d1_unco...  boxing"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/KTH/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['boxing', 'handclapping', 'handwaving', 'jogging', 'running', 'walking'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_class(x):\n",
    "    if x not in ['golf', 'kick_ball', 'pushup', 'shoot_ball',  \n",
    "             'shoot_bow', 'shoot_gun', 'swing_baseball', \n",
    "             'thow', 'BoxingPunchingBag', 'boxing', 'punch', \n",
    "             'kick', 'point', 'handwaving', 'wave']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(three_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_df = []\n",
    "\n",
    "for i in df['label'].unique():\n",
    "    classwise_df.append(df[df['label']==i].reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('models/yolov8m-pose.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "for df in classwise_df:\n",
    "    total_df = pd.concat([total_df, df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index                                          clip_path  label\n",
      "369    569  ../datasets/KTH/walking\\person18_walking_d3_un...      0\n",
      "289    489  ../datasets/KTH/running\\person23_running_d3_un...      0\n",
      "56     156  ../datasets/KTH/handclapping\\person15_handclap...      0\n",
      "352    552  ../datasets/KTH/walking\\person14_walking_d2_un...      0\n",
      "    index                                          clip_path  label\n",
      "88     88  ../datasets/KTH/boxing\\person23_boxing_d1_unco...      1\n"
     ]
    }
   ],
   "source": [
    "for i, d in total_df.sample(5).groupby('label'):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import os\n",
    "\n",
    "def data_generator(total_df, batch_size=1, shuffle_data=True, resize=320):\n",
    "    \"\"\"\n",
    "    Yields the next training batch.\n",
    "    Suppose `total_df` is a pandas DataFrame with columns 'clip_path' and 'label'.\n",
    "    \"\"\"\n",
    "    num_samples = len(total_df)\n",
    "    samples = list(total_df.iterrows())  # Convert DataFrame to a list of (index, row) tuples\n",
    "\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "        if shuffle_data:\n",
    "            shuffle(samples)\n",
    "\n",
    "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size <= num_samples]\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            # Get the samples you'll use in this batch\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            # Initialise pose_buffer and labels arrays for this batch\n",
    "            pose_buffer = []\n",
    "            rbg_buffer = []\n",
    "            labels = []\n",
    "\n",
    "            # For each example\n",
    "            for _, batch_sample in batch_samples:\n",
    "                # Load video (X) and label (y)\n",
    "                vid_path = batch_sample['clip_path']\n",
    "                label = batch_sample['label']\n",
    "                cap = cv2.VideoCapture(vid_path)\n",
    "                frame_buffer = []\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        cap.release()\n",
    "                        break\n",
    "\n",
    "                    frame = cv2.resize(frame, (resize, resize))\n",
    "                    if len(frame_buffer) < 10:\n",
    "                        frame_buffer.append(frame)\n",
    "                    elif len(frame_buffer) == 10:\n",
    "                        batch = vp.process_video(frame_buffer)\n",
    "                        batch = np.array(batch)[:, 0, :].reshape(-1, 10, 34)\n",
    "                        pose_buffer.append(batch[0])\n",
    "                        rbg_buffer.append(frame)\n",
    "                        frame_buffer = []\n",
    "                        labels.append(label)\n",
    "                    else:\n",
    "                        frame_buffer = []\n",
    "\n",
    "                # labels.extend([label] * len(pose_buffer))  # Extend the labels list for this video's frames\n",
    "\n",
    "            # Make sure they're numpy arrays (as opposed to lists)\n",
    "            pose_buffer = np.array(pose_buffer)\n",
    "            rbg_buffer = np.array(rbg_buffer)\n",
    "            labels = np.array(labels)\n",
    "            # print(len(labels))\n",
    "\n",
    "\n",
    "            # res = [pose_buffer, rbg_buffer], labels\n",
    "            # print(res[0][0].shape, res[0][1].shape, res[1].shape)\n",
    "\n",
    "            # The generator-y part: yield the next training batch\n",
    "            yield [pose_buffer, rbg_buffer], labels  # ([(None, 10, 34), (None, 640, 640, 3)], (None,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = VideoProcessor(model, max_frames=100, img_sz=320, show_stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# total_df = total_df[:10]\n",
    "train_df, test_df = train_test_split(total_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df  = train_test_split(total_df, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "599/599 [==============================] - 1533s 3s/step - loss: 0.5447 - accuracy: 0.6795 - binary_accuracy: 0.6795\n",
      "Epoch 2/4\n",
      "599/599 [==============================] - 1599s 3s/step - loss: 0.4842 - accuracy: 0.6760 - binary_accuracy: 0.6760\n",
      "Epoch 3/4\n",
      "599/599 [==============================] - 1515s 3s/step - loss: 0.4624 - accuracy: 0.7039 - binary_accuracy: 0.7039\n",
      "Epoch 4/4\n",
      "599/599 [==============================] - 1515s 3s/step - loss: 0.4469 - accuracy: 0.7526 - binary_accuracy: 0.7526\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 4\n",
    "train_generator = data_generator(train_df, batch_size=batch_size)\n",
    "val_generator = data_generator(val_df, batch_size=batch_size)\n",
    "steps_per_epoch = len(total_df) // batch_size\n",
    "# steps_per_epoch = 10\n",
    "# Now, you can use this generator to train your model\n",
    "history = fusion_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,)\n",
    "                        #    validation_data = val_generator, validation_steps=steps_per_epoch//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "599/599 [==============================] - 1497s 3s/step - loss: 0.4247 - accuracy: 0.7474 - binary_accuracy: 0.7474\n",
      "Epoch 2/25\n",
      "599/599 [==============================] - 1869s 3s/step - loss: 0.4142 - accuracy: 0.7587 - binary_accuracy: 0.7587\n",
      "Epoch 3/25\n",
      "599/599 [==============================] - 1940s 3s/step - loss: 0.4040 - accuracy: 0.7642 - binary_accuracy: 0.7642\n",
      "Epoch 4/25\n",
      "599/599 [==============================] - 1978s 3s/step - loss: 0.4202 - accuracy: 0.7811 - binary_accuracy: 0.7811\n",
      "Epoch 5/25\n",
      "599/599 [==============================] - 2017s 3s/step - loss: 0.3969 - accuracy: 0.7725 - binary_accuracy: 0.7725\n",
      "Epoch 6/25\n",
      "599/599 [==============================] - 2038s 3s/step - loss: 0.4078 - accuracy: 0.7785 - binary_accuracy: 0.7785\n",
      "Epoch 7/25\n",
      "599/599 [==============================] - 2075s 3s/step - loss: 0.4232 - accuracy: 0.7602 - binary_accuracy: 0.7602\n",
      "Epoch 8/25\n",
      "599/599 [==============================] - 2542s 4s/step - loss: 0.3787 - accuracy: 0.7943 - binary_accuracy: 0.7943\n",
      "Epoch 9/25\n",
      "599/599 [==============================] - 3027s 5s/step - loss: 0.4664 - accuracy: 0.7787 - binary_accuracy: 0.7787\n",
      "Epoch 10/25\n",
      "599/599 [==============================] - 3055s 5s/step - loss: 0.4140 - accuracy: 0.7812 - binary_accuracy: 0.7812\n",
      "Epoch 11/25\n",
      "599/599 [==============================] - 3101s 5s/step - loss: 0.3832 - accuracy: 0.7900 - binary_accuracy: 0.7900\n",
      "Epoch 12/25\n",
      "599/599 [==============================] - 2887s 5s/step - loss: 0.3650 - accuracy: 0.8007 - binary_accuracy: 0.8007\n",
      "Epoch 13/25\n",
      "599/599 [==============================] - 2984s 5s/step - loss: 0.3613 - accuracy: 0.8074 - binary_accuracy: 0.8074\n",
      "Epoch 14/25\n",
      "599/599 [==============================] - 2879s 5s/step - loss: 0.3473 - accuracy: 0.8193 - binary_accuracy: 0.8193\n",
      "Epoch 15/25\n",
      "599/599 [==============================] - 2937s 5s/step - loss: 0.3220 - accuracy: 0.8372 - binary_accuracy: 0.8372\n",
      "Epoch 16/25\n",
      "599/599 [==============================] - 2930s 5s/step - loss: 0.3079 - accuracy: 0.8448 - binary_accuracy: 0.8448\n",
      "Epoch 17/25\n",
      "599/599 [==============================] - 2876s 5s/step - loss: 0.3072 - accuracy: 0.8531 - binary_accuracy: 0.8531\n",
      "Epoch 18/25\n",
      "410/599 [===================>..........] - ETA: 15:20 - loss: 0.3035 - accuracy: 0.8604 - binary_accuracy: 0.8604"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 25\n",
    "history1 = fusion_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model.save('models/rbg_lstm_checkpoint_30_epochs.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
